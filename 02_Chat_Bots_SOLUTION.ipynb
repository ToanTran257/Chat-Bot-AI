{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "02-Chat-Bots-SOLUTION.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4-rUG7Xadu4",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Question and Answer Chat Bots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiB8JVB1adu7",
        "colab_type": "text"
      },
      "source": [
        "## Loading the Data\n",
        "\n",
        "We will be working with the Babi Data Set from Facebook Research.\n",
        "\n",
        "Full Details: https://research.fb.com/downloads/babi/\n",
        "\n",
        "- Jason Weston, Antoine Bordes, Sumit Chopra, Tomas Mikolov, Alexander M. Rush,\n",
        "  \"Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks\",\n",
        "  http://arxiv.org/abs/1502.05698\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyrWW6BDadu8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kk1LjuAwadu-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"train_qa.txt\", \"rb\") as fp:   # Unpickling\n",
        "    train_data =  pickle.load(fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7YYg4kNadvA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"test_qa.txt\", \"rb\") as fp:   # Unpickling\n",
        "    test_data =  pickle.load(fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hWxjgZDadvB",
        "colab_type": "text"
      },
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJnEAAJSadvC",
        "colab_type": "text"
      },
      "source": [
        "## Exploring the Format of the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4C8ATKpadvC",
        "colab_type": "code",
        "outputId": "83f5f582-7a99-48ea-ae7d-d5f4d731fb83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(test_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIX-qZg-advE",
        "colab_type": "code",
        "outputId": "54f72941-840c-403c-c528-182713d486dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(train_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8UvyBViadvF",
        "colab_type": "code",
        "outputId": "862f2904-c1db-4f0e-f6a2-65210ac24bd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(test_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5U1z-bvadvI",
        "colab_type": "code",
        "outputId": "444af86a-4c04-421f-f264-fea99bbbea40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtaLDGX0advJ",
        "colab_type": "code",
        "outputId": "a315fa62-b889-417e-c6c2-9d3a7f2e44cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "train_data[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['Mary',\n",
              "  'moved',\n",
              "  'to',\n",
              "  'the',\n",
              "  'bathroom',\n",
              "  '.',\n",
              "  'Sandra',\n",
              "  'journeyed',\n",
              "  'to',\n",
              "  'the',\n",
              "  'bedroom',\n",
              "  '.'],\n",
              " ['Is', 'Sandra', 'in', 'the', 'hallway', '?'],\n",
              " 'no')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaWCxFM5advL",
        "colab_type": "code",
        "outputId": "77fdef96-c486-4eea-fd38-ee1fb0e77285",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "' '.join(train_data[3][0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Mary moved to the bathroom . Sandra journeyed to the bedroom . Mary went back to the bedroom . Daniel went back to the hallway . Sandra went to the kitchen . Daniel went back to the bathroom . Daniel picked up the football there . Daniel went to the bedroom .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FLTUhl7advN",
        "colab_type": "code",
        "outputId": "373c0dc1-650d-4039-8f88-6d94cc6135d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "' '.join(train_data[3][1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Is Daniel in the bedroom ?'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3Eqlf8padvP",
        "colab_type": "code",
        "outputId": "769265dd-b28f-4605-fe21-03ca92b08af2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# train_data[3][2]\n",
        "\n",
        "for x in range(10):\n",
        "  print(train_data[x][2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "no\n",
            "no\n",
            "no\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "no\n",
            "no\n",
            "no\n",
            "yes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjYF4wdHadvQ",
        "colab_type": "text"
      },
      "source": [
        "-----\n",
        "\n",
        "## Setting up Vocabulary of All Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LFzIjP0advQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a set that holds the vocab words\n",
        "vocab = set()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AGYf1rLadvS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_data = test_data + train_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f53KVgTYadvU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for story, question , answer in all_data:\n",
        "    # In case you don't know what a union of sets is:\n",
        "    # https://www.programiz.com/python-programming/methods/set/union\n",
        "    vocab = vocab.union(set(story))\n",
        "    vocab = vocab.union(set(question))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ba6Edfl5advV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab.add('no')\n",
        "vocab.add('yes')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4HEBaEWadvW",
        "colab_type": "code",
        "outputId": "b078617d-945c-4501-f93b-1256191ebd58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        }
      },
      "source": [
        "vocab"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.',\n",
              " '?',\n",
              " 'Daniel',\n",
              " 'Is',\n",
              " 'John',\n",
              " 'Mary',\n",
              " 'Sandra',\n",
              " 'apple',\n",
              " 'back',\n",
              " 'bathroom',\n",
              " 'bedroom',\n",
              " 'discarded',\n",
              " 'down',\n",
              " 'dropped',\n",
              " 'football',\n",
              " 'garden',\n",
              " 'got',\n",
              " 'grabbed',\n",
              " 'hallway',\n",
              " 'in',\n",
              " 'journeyed',\n",
              " 'kitchen',\n",
              " 'left',\n",
              " 'milk',\n",
              " 'moved',\n",
              " 'no',\n",
              " 'office',\n",
              " 'picked',\n",
              " 'put',\n",
              " 'the',\n",
              " 'there',\n",
              " 'to',\n",
              " 'took',\n",
              " 'travelled',\n",
              " 'up',\n",
              " 'went',\n",
              " 'yes'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6-1qsh3advY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_len = len(vocab) + 1 #we add an extra space to hold a 0 for Keras's pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nu_biBa2advZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_story_len = max([len(data[0]) for data in all_data])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPuSMvOiadvb",
        "colab_type": "code",
        "outputId": "3c572536-27c8-4964-ee9d-a89a32b36690",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max_story_len"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "156"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ME_ydMt_advf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_question_len = max([len(data[1]) for data in all_data])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_sSzs5gadvh",
        "colab_type": "code",
        "outputId": "21a2f4a6-3e49-4cb7-f912-8efc2f55c68f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max_question_len"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kzKXqy3advi",
        "colab_type": "text"
      },
      "source": [
        "## Vectorizing the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vfvYngCadvj",
        "colab_type": "code",
        "outputId": "7a003f22-6fa3-4809-c3e3-179ef2f2cc9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        }
      },
      "source": [
        "vocab"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.',\n",
              " '?',\n",
              " 'Daniel',\n",
              " 'Is',\n",
              " 'John',\n",
              " 'Mary',\n",
              " 'Sandra',\n",
              " 'apple',\n",
              " 'back',\n",
              " 'bathroom',\n",
              " 'bedroom',\n",
              " 'discarded',\n",
              " 'down',\n",
              " 'dropped',\n",
              " 'football',\n",
              " 'garden',\n",
              " 'got',\n",
              " 'grabbed',\n",
              " 'hallway',\n",
              " 'in',\n",
              " 'journeyed',\n",
              " 'kitchen',\n",
              " 'left',\n",
              " 'milk',\n",
              " 'moved',\n",
              " 'no',\n",
              " 'office',\n",
              " 'picked',\n",
              " 'put',\n",
              " 'the',\n",
              " 'there',\n",
              " 'to',\n",
              " 'took',\n",
              " 'travelled',\n",
              " 'up',\n",
              " 'went',\n",
              " 'yes'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTKnn2jiadvk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reserve 0 for pad_sequences\n",
        "vocab_size = len(vocab) + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33wwiYmTadvl",
        "colab_type": "text"
      },
      "source": [
        "-----------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bM3EEvENadvm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9ac_dGRadvn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# integer encode sequences of words\n",
        "tokenizer = Tokenizer(filters=[])\n",
        "tokenizer.fit_on_texts(vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VT3_P-Oiadvp",
        "colab_type": "code",
        "outputId": "068e2307-6878-49d5-b98d-9449243583ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        }
      },
      "source": [
        "tokenizer.word_index"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.': 20,\n",
              " '?': 31,\n",
              " 'apple': 30,\n",
              " 'back': 9,\n",
              " 'bathroom': 29,\n",
              " 'bedroom': 28,\n",
              " 'daniel': 22,\n",
              " 'discarded': 33,\n",
              " 'down': 7,\n",
              " 'dropped': 37,\n",
              " 'football': 24,\n",
              " 'garden': 4,\n",
              " 'got': 8,\n",
              " 'grabbed': 25,\n",
              " 'hallway': 16,\n",
              " 'in': 1,\n",
              " 'is': 3,\n",
              " 'john': 14,\n",
              " 'journeyed': 5,\n",
              " 'kitchen': 19,\n",
              " 'left': 35,\n",
              " 'mary': 23,\n",
              " 'milk': 6,\n",
              " 'moved': 15,\n",
              " 'no': 2,\n",
              " 'office': 34,\n",
              " 'picked': 36,\n",
              " 'put': 18,\n",
              " 'sandra': 11,\n",
              " 'the': 32,\n",
              " 'there': 21,\n",
              " 'to': 17,\n",
              " 'took': 12,\n",
              " 'travelled': 26,\n",
              " 'up': 13,\n",
              " 'went': 27,\n",
              " 'yes': 10}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHlDxebDadvq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_story_text = []\n",
        "train_question_text = []\n",
        "train_answers = []\n",
        "\n",
        "for story,question,answer in train_data:\n",
        "    train_story_text.append(story)\n",
        "    train_question_text.append(question)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpYfdUSCadvs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_story_seq = tokenizer.texts_to_sequences(train_story_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9SpIGF7advt",
        "colab_type": "code",
        "outputId": "b4f9afd0-4326-4764-8957-52057370a82b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train_story_text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mer3URpadvv",
        "colab_type": "code",
        "outputId": "353f3243-79a5-452a-8a8c-d39a96787d53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train_story_seq)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQk0TaFZadvx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# word_index = tokenizer.word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqe3elfSadvy",
        "colab_type": "text"
      },
      "source": [
        "### Functionalize Vectorization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iw2uvyD3advy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vectorize_stories(data, \n",
        "                      word_index=tokenizer.word_index, \n",
        "                      max_story_len=max_story_len,\n",
        "                      max_question_len=max_question_len):\n",
        "    '''\n",
        "    INPUT: \n",
        "    \n",
        "    data: consisting of Stories,Queries,and Answers\n",
        "    word_index: word index dictionary from tokenizer\n",
        "    max_story_len: the length of the longest story (used for pad_sequences function)\n",
        "    max_question_len: length of the longest question (used for pad_sequences function)\n",
        "\n",
        "\n",
        "    OUTPUT:\n",
        "    \n",
        "    Vectorizes the stories,questions, and answers into padded sequences. We first loop for every story, query , and\n",
        "    answer in the data. Then we convert the raw words to an word index value. Then we append each set to their appropriate\n",
        "    output list. Then once we have converted the words to numbers, we pad the sequences so they are all of equal length.\n",
        "    \n",
        "    Returns this in the form of a tuple (X,Xq,Y) (padded based on max lengths)\n",
        "    '''\n",
        "    \n",
        "    \n",
        "    # X = STORIES\n",
        "    X = []\n",
        "    # Xq = QUERY/QUESTION\n",
        "    Xq = []\n",
        "    # Y = CORRECT ANSWER\n",
        "    Y = []\n",
        "    \n",
        "    \n",
        "    for story, query, answer in data:\n",
        "        \n",
        "        # Grab the word index for every word in story\n",
        "        x = [word_index[word.lower()] for word in story]\n",
        "        # Grab the word index for every word in query\n",
        "        xq = [word_index[word.lower()] for word in query]\n",
        "        \n",
        "        # Grab the Answers (either Yes/No so we don't need to use list comprehension here)\n",
        "        # Index 0 is reserved so we're going to use + 1\n",
        "        y = np.zeros(len(word_index) + 1)\n",
        "        \n",
        "        # Now that y is all zeros and we know its just Yes/No , we can use numpy logic to create this assignment\n",
        "        #\n",
        "        y[word_index[answer]] = 1\n",
        "        \n",
        "        # Append each set of story,query, and answer to their respective holding lists\n",
        "        X.append(x)\n",
        "        Xq.append(xq)\n",
        "        Y.append(y)\n",
        "        \n",
        "    # Finally, pad the sequences based on their max length so the RNN can be trained on uniformly long sequences.\n",
        "        \n",
        "    # RETURN TUPLE FOR UNPACKING\n",
        "    return (pad_sequences(X, maxlen=max_story_len),pad_sequences(Xq, maxlen=max_question_len), np.array(Y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nOWyIcIadv0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs_train, queries_train, answers_train = vectorize_stories(train_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ninmgsiXadv1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs_test, queries_test, answers_test = vectorize_stories(test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y99Ik6aSadv2",
        "colab_type": "code",
        "outputId": "90bde365-8886-406e-f448-8fc27be6232b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "inputs_test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0, ..., 32, 28, 20],\n",
              "       [ 0,  0,  0, ..., 32,  4, 20],\n",
              "       [ 0,  0,  0, ..., 32,  4, 20],\n",
              "       ...,\n",
              "       [ 0,  0,  0, ..., 32, 30, 20],\n",
              "       [ 0,  0,  0, ..., 32,  4, 20],\n",
              "       [ 0,  0,  0, ..., 30, 21, 20]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSQxVyoWadv4",
        "colab_type": "code",
        "outputId": "3b07dba8-37f0-4b60-b53d-b1e36983be6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "queries_test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 3, 14,  1, 32, 19, 31],\n",
              "       [ 3, 14,  1, 32, 19, 31],\n",
              "       [ 3, 14,  1, 32,  4, 31],\n",
              "       ...,\n",
              "       [ 3, 23,  1, 32, 28, 31],\n",
              "       [ 3, 11,  1, 32,  4, 31],\n",
              "       [ 3, 23,  1, 32,  4, 31]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUrnrahNadv5",
        "colab_type": "code",
        "outputId": "66ce6a60-402f-42f3-b880-7f55b7d0e9ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "answers_test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 1., ..., 0., 0., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpTxzyRuadv7",
        "colab_type": "code",
        "outputId": "3ce1df90-9543-44a0-a218-3df9a307b332",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "sum(answers_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0.,   0., 503.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 497.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Okzh-sWnadv8",
        "colab_type": "code",
        "outputId": "c9957843-479c-4bef-d014-c6994e83eb0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tokenizer.word_index['yes']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wb2UIup8adv9",
        "colab_type": "code",
        "outputId": "4d961db0-7291-4883-ef10-f6d502990bd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tokenizer.word_index['no']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMrzWXLaadv_",
        "colab_type": "text"
      },
      "source": [
        "## Creating the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g72Fvq6Hadv_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers import Input, Activation, Dense, Permute, Dropout\n",
        "from keras.layers import add, dot, concatenate\n",
        "from keras.layers import LSTM"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zO10NZSPadwG",
        "colab_type": "text"
      },
      "source": [
        "### Placeholders for Inputs\n",
        "\n",
        "Recall we technically have two inputs, stories and questions. So we need to use placeholders. `Input()` is used to instantiate a Keras tensor.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nq0NB6FladwH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_sequence = Input((max_story_len,))\n",
        "question = Input((max_question_len,))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "sQC2qdq3adwK",
        "colab_type": "text"
      },
      "source": [
        "### Building the Networks\n",
        "\n",
        "To understand why we chose this setup, make sure to read the paper we are using:\n",
        "\n",
        "* Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, Rob Fergus,\n",
        "  \"End-To-End Memory Networks\",\n",
        "  http://arxiv.org/abs/1503.08895"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9R9fsNU7adwK",
        "colab_type": "text"
      },
      "source": [
        "## Encoders\n",
        "\n",
        "### Input Encoder m"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDpvRyqkadwK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Input gets embedded to a sequence of vectors\n",
        "input_encoder_m = Sequential()\n",
        "input_encoder_m.add(Embedding(input_dim=vocab_size,output_dim=128))\n",
        "input_encoder_m.add(Dropout(0.3))\n",
        "\n",
        "# This encoder will output:\n",
        "# (samples, story_maxlen, embedding_dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_t4Xe7kadwM",
        "colab_type": "text"
      },
      "source": [
        "### Input Encoder c"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3tH3868adwM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# embed the input into a sequence of vectors of size query_maxlen\n",
        "input_encoder_c = Sequential()\n",
        "input_encoder_c.add(Embedding(input_dim=vocab_size,output_dim=max_question_len))\n",
        "input_encoder_c.add(Dropout(0.3))\n",
        "# output: (samples, story_maxlen, query_maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nU4si9kJadwO",
        "colab_type": "text"
      },
      "source": [
        "### Question Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80mphfNiadwO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# embed the question into a sequence of vectors\n",
        "question_encoder = Sequential()\n",
        "question_encoder.add(Embedding(input_dim=vocab_size,\n",
        "                               output_dim=128,\n",
        "                               input_length=max_question_len))\n",
        "question_encoder.add(Dropout(0.3))\n",
        "# output: (samples, query_maxlen, embedding_dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0J5y6J3adwQ",
        "colab_type": "text"
      },
      "source": [
        "### Encode the Sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xs4UssAhadwQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encode input sequence and questions (which are indices)\n",
        "# to sequences of dense vectors\n",
        "input_encoded_m = input_encoder_m(input_sequence)\n",
        "input_encoded_c = input_encoder_c(input_sequence)\n",
        "question_encoded = question_encoder(question)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5EjSAnGadwR",
        "colab_type": "text"
      },
      "source": [
        "##### Use dot product to compute the match between first input vector seq and the query"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8UA8auXadwR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# shape: `(samples, story_maxlen, query_maxlen)`\n",
        "match = dot([input_encoded_m, question_encoded], axes=(2, 2))\n",
        "match = Activation('sigmoid')(match)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mB-fBpoUadwS",
        "colab_type": "text"
      },
      "source": [
        "#### Add this match matrix with the second input vector sequence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxN7UArwadwT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add the match matrix with the second input vector sequence\n",
        "response = add([match, input_encoded_c])  # (samples, story_maxlen, query_maxlen)\n",
        "response = Permute((2, 1))(response)  # (samples, query_maxlen, story_maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTmaNq-vadwU",
        "colab_type": "text"
      },
      "source": [
        "#### Concatenate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dt0LOW_BadwU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# concatenate the match matrix with the question vector sequence\n",
        "answer = concatenate([response, question_encoded])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPeTOcafadwV",
        "colab_type": "code",
        "outputId": "37262713-a5eb-44a5-b20c-eca4fa4b7f15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "answer"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'concatenate_3/concat:0' shape=(?, 6, 284) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 194
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pf_lsnExadwW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reduce with RNN (LSTM)\n",
        "answer = LSTM(32)(answer)  # (samples, 32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gFkQ5YvadwX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Regularization with Dropout\n",
        "answer = Dropout(0.5)(answer)\n",
        "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5gspCw4adwY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we output a probability distribution over the vocabulary\n",
        "answer = Activation('sigmoid')(answer)\n",
        "\n",
        "# build the final model\n",
        "model = Model([input_sequence, question], answer)\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38CpscPuadwZ",
        "colab_type": "code",
        "outputId": "81e4f368-4bdb-48c6-e52f-c297dd379565",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            (None, 156)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_6 (InputLayer)            (None, 6)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential_7 (Sequential)       multiple             4864        input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "sequential_9 (Sequential)       (None, 6, 128)       4864        input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dot_3 (Dot)                     (None, 156, 6)       0           sequential_7[1][0]               \n",
            "                                                                 sequential_9[1][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 156, 6)       0           dot_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "sequential_8 (Sequential)       multiple             228         input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 156, 6)       0           activation_5[0][0]               \n",
            "                                                                 sequential_8[1][0]               \n",
            "__________________________________________________________________________________________________\n",
            "permute_3 (Permute)             (None, 6, 156)       0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 6, 284)       0           permute_3[0][0]                  \n",
            "                                                                 sequential_9[1][0]               \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   (None, 32)           40576       concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 32)           0           lstm_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 38)           1254        dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 38)           0           dense_3[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 51,786\n",
            "Trainable params: 51,786\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qe0RViSJadwa",
        "colab_type": "code",
        "outputId": "231a3f4f-531c-4023-9171-a95defb72146",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# train\n",
        "history = model.fit([inputs_train, queries_train], answers_train,batch_size=32,epochs=100,validation_data=([inputs_test, queries_test], answers_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 10000 samples, validate on 1000 samples\n",
            "Epoch 1/100\n",
            "10000/10000 [==============================] - 7s 745us/step - loss: 0.1123 - acc: 0.9547 - val_loss: 0.0367 - val_acc: 0.9735\n",
            "Epoch 2/100\n",
            "10000/10000 [==============================] - 6s 615us/step - loss: 0.0382 - acc: 0.9737 - val_loss: 0.0365 - val_acc: 0.9735\n",
            "Epoch 3/100\n",
            "10000/10000 [==============================] - 6s 608us/step - loss: 0.0369 - acc: 0.9738 - val_loss: 0.0365 - val_acc: 0.9738\n",
            "Epoch 4/100\n",
            "10000/10000 [==============================] - 6s 617us/step - loss: 0.0367 - acc: 0.9736 - val_loss: 0.0365 - val_acc: 0.9738\n",
            "Epoch 5/100\n",
            "10000/10000 [==============================] - 6s 622us/step - loss: 0.0366 - acc: 0.9738 - val_loss: 0.0365 - val_acc: 0.9735\n",
            "Epoch 6/100\n",
            "10000/10000 [==============================] - 6s 620us/step - loss: 0.0366 - acc: 0.9734 - val_loss: 0.0365 - val_acc: 0.9738\n",
            "Epoch 7/100\n",
            "10000/10000 [==============================] - 6s 612us/step - loss: 0.0365 - acc: 0.9738 - val_loss: 0.0365 - val_acc: 0.9738\n",
            "Epoch 8/100\n",
            "10000/10000 [==============================] - 6s 611us/step - loss: 0.0365 - acc: 0.9738 - val_loss: 0.0366 - val_acc: 0.9738\n",
            "Epoch 9/100\n",
            "10000/10000 [==============================] - 6s 608us/step - loss: 0.0365 - acc: 0.9738 - val_loss: 0.0365 - val_acc: 0.9735\n",
            "Epoch 10/100\n",
            "10000/10000 [==============================] - 6s 613us/step - loss: 0.0365 - acc: 0.9739 - val_loss: 0.0365 - val_acc: 0.9735\n",
            "Epoch 11/100\n",
            "10000/10000 [==============================] - 6s 611us/step - loss: 0.0365 - acc: 0.9741 - val_loss: 0.0365 - val_acc: 0.9735\n",
            "Epoch 12/100\n",
            "10000/10000 [==============================] - 6s 603us/step - loss: 0.0365 - acc: 0.9737 - val_loss: 0.0365 - val_acc: 0.9738\n",
            "Epoch 13/100\n",
            "10000/10000 [==============================] - 6s 611us/step - loss: 0.0365 - acc: 0.9734 - val_loss: 0.0366 - val_acc: 0.9735\n",
            "Epoch 14/100\n",
            "10000/10000 [==============================] - 6s 609us/step - loss: 0.0365 - acc: 0.9742 - val_loss: 0.0366 - val_acc: 0.9735\n",
            "Epoch 15/100\n",
            "10000/10000 [==============================] - 6s 614us/step - loss: 0.0365 - acc: 0.9736 - val_loss: 0.0365 - val_acc: 0.9739\n",
            "Epoch 16/100\n",
            "10000/10000 [==============================] - 6s 607us/step - loss: 0.0365 - acc: 0.9735 - val_loss: 0.0365 - val_acc: 0.9730\n",
            "Epoch 17/100\n",
            "10000/10000 [==============================] - 6s 633us/step - loss: 0.0364 - acc: 0.9745 - val_loss: 0.0365 - val_acc: 0.9733\n",
            "Epoch 18/100\n",
            "10000/10000 [==============================] - 6s 618us/step - loss: 0.0362 - acc: 0.9757 - val_loss: 0.0359 - val_acc: 0.9758\n",
            "Epoch 19/100\n",
            "10000/10000 [==============================] - 6s 608us/step - loss: 0.0352 - acc: 0.9777 - val_loss: 0.0344 - val_acc: 0.9784\n",
            "Epoch 20/100\n",
            "10000/10000 [==============================] - 6s 620us/step - loss: 0.0343 - acc: 0.9795 - val_loss: 0.0337 - val_acc: 0.9803\n",
            "Epoch 21/100\n",
            "10000/10000 [==============================] - 6s 613us/step - loss: 0.0332 - acc: 0.9807 - val_loss: 0.0328 - val_acc: 0.9806\n",
            "Epoch 22/100\n",
            "10000/10000 [==============================] - 6s 605us/step - loss: 0.0324 - acc: 0.9818 - val_loss: 0.0321 - val_acc: 0.9820\n",
            "Epoch 23/100\n",
            "10000/10000 [==============================] - 6s 610us/step - loss: 0.0311 - acc: 0.9832 - val_loss: 0.0306 - val_acc: 0.9833\n",
            "Epoch 24/100\n",
            "10000/10000 [==============================] - 6s 612us/step - loss: 0.0301 - acc: 0.9839 - val_loss: 0.0289 - val_acc: 0.9852\n",
            "Epoch 25/100\n",
            "10000/10000 [==============================] - 6s 603us/step - loss: 0.0291 - acc: 0.9852 - val_loss: 0.0281 - val_acc: 0.9858\n",
            "Epoch 26/100\n",
            "10000/10000 [==============================] - 6s 605us/step - loss: 0.0281 - acc: 0.9862 - val_loss: 0.0281 - val_acc: 0.9860\n",
            "Epoch 27/100\n",
            "10000/10000 [==============================] - 6s 605us/step - loss: 0.0273 - acc: 0.9866 - val_loss: 0.0265 - val_acc: 0.9871\n",
            "Epoch 28/100\n",
            "10000/10000 [==============================] - 6s 600us/step - loss: 0.0261 - acc: 0.9876 - val_loss: 0.0256 - val_acc: 0.9874\n",
            "Epoch 29/100\n",
            "10000/10000 [==============================] - 6s 597us/step - loss: 0.0257 - acc: 0.9879 - val_loss: 0.0255 - val_acc: 0.9877\n",
            "Epoch 30/100\n",
            "10000/10000 [==============================] - 6s 606us/step - loss: 0.0248 - acc: 0.9883 - val_loss: 0.0239 - val_acc: 0.9889\n",
            "Epoch 31/100\n",
            "10000/10000 [==============================] - 6s 598us/step - loss: 0.0242 - acc: 0.9891 - val_loss: 0.0231 - val_acc: 0.9889\n",
            "Epoch 32/100\n",
            "10000/10000 [==============================] - 6s 611us/step - loss: 0.0235 - acc: 0.9897 - val_loss: 0.0233 - val_acc: 0.9891\n",
            "Epoch 33/100\n",
            "10000/10000 [==============================] - 6s 605us/step - loss: 0.0226 - acc: 0.9899 - val_loss: 0.0225 - val_acc: 0.9895\n",
            "Epoch 34/100\n",
            "10000/10000 [==============================] - 6s 611us/step - loss: 0.0222 - acc: 0.9900 - val_loss: 0.0223 - val_acc: 0.9902\n",
            "Epoch 35/100\n",
            "10000/10000 [==============================] - 6s 601us/step - loss: 0.0219 - acc: 0.9902 - val_loss: 0.0240 - val_acc: 0.9893\n",
            "Epoch 36/100\n",
            "10000/10000 [==============================] - 6s 598us/step - loss: 0.0214 - acc: 0.9903 - val_loss: 0.0221 - val_acc: 0.9901\n",
            "Epoch 37/100\n",
            "10000/10000 [==============================] - 6s 606us/step - loss: 0.0214 - acc: 0.9905 - val_loss: 0.0205 - val_acc: 0.9909\n",
            "Epoch 38/100\n",
            "10000/10000 [==============================] - 6s 597us/step - loss: 0.0207 - acc: 0.9910 - val_loss: 0.0212 - val_acc: 0.9903\n",
            "Epoch 39/100\n",
            "10000/10000 [==============================] - 6s 602us/step - loss: 0.0206 - acc: 0.9911 - val_loss: 0.0214 - val_acc: 0.9903\n",
            "Epoch 40/100\n",
            "10000/10000 [==============================] - 6s 605us/step - loss: 0.0204 - acc: 0.9912 - val_loss: 0.0223 - val_acc: 0.9897\n",
            "Epoch 41/100\n",
            "10000/10000 [==============================] - 6s 600us/step - loss: 0.0195 - acc: 0.9916 - val_loss: 0.0233 - val_acc: 0.9899\n",
            "Epoch 42/100\n",
            "10000/10000 [==============================] - 6s 606us/step - loss: 0.0190 - acc: 0.9921 - val_loss: 0.0199 - val_acc: 0.9907\n",
            "Epoch 43/100\n",
            "10000/10000 [==============================] - 6s 600us/step - loss: 0.0185 - acc: 0.9922 - val_loss: 0.0204 - val_acc: 0.9908\n",
            "Epoch 44/100\n",
            "10000/10000 [==============================] - 6s 604us/step - loss: 0.0186 - acc: 0.9922 - val_loss: 0.0207 - val_acc: 0.9907\n",
            "Epoch 45/100\n",
            "10000/10000 [==============================] - 6s 609us/step - loss: 0.0183 - acc: 0.9924 - val_loss: 0.0202 - val_acc: 0.9907\n",
            "Epoch 46/100\n",
            "10000/10000 [==============================] - 6s 600us/step - loss: 0.0179 - acc: 0.9925 - val_loss: 0.0220 - val_acc: 0.9902\n",
            "Epoch 47/100\n",
            "10000/10000 [==============================] - 6s 594us/step - loss: 0.0180 - acc: 0.9924 - val_loss: 0.0196 - val_acc: 0.9910\n",
            "Epoch 48/100\n",
            "10000/10000 [==============================] - 6s 605us/step - loss: 0.0180 - acc: 0.9924 - val_loss: 0.0197 - val_acc: 0.9909\n",
            "Epoch 49/100\n",
            "10000/10000 [==============================] - 6s 602us/step - loss: 0.0174 - acc: 0.9925 - val_loss: 0.0204 - val_acc: 0.9901\n",
            "Epoch 50/100\n",
            "10000/10000 [==============================] - 6s 596us/step - loss: 0.0172 - acc: 0.9926 - val_loss: 0.0200 - val_acc: 0.9912\n",
            "Epoch 51/100\n",
            "10000/10000 [==============================] - 6s 601us/step - loss: 0.0174 - acc: 0.9924 - val_loss: 0.0185 - val_acc: 0.9915\n",
            "Epoch 52/100\n",
            "10000/10000 [==============================] - 6s 601us/step - loss: 0.0173 - acc: 0.9927 - val_loss: 0.0203 - val_acc: 0.9910\n",
            "Epoch 53/100\n",
            "10000/10000 [==============================] - 6s 602us/step - loss: 0.0172 - acc: 0.9926 - val_loss: 0.0186 - val_acc: 0.9913\n",
            "Epoch 54/100\n",
            "10000/10000 [==============================] - 6s 598us/step - loss: 0.0171 - acc: 0.9927 - val_loss: 0.0189 - val_acc: 0.9909\n",
            "Epoch 55/100\n",
            "10000/10000 [==============================] - 6s 600us/step - loss: 0.0169 - acc: 0.9926 - val_loss: 0.0196 - val_acc: 0.9911\n",
            "Epoch 56/100\n",
            "10000/10000 [==============================] - 6s 606us/step - loss: 0.0170 - acc: 0.9927 - val_loss: 0.0202 - val_acc: 0.9912\n",
            "Epoch 57/100\n",
            "10000/10000 [==============================] - 6s 596us/step - loss: 0.0169 - acc: 0.9927 - val_loss: 0.0190 - val_acc: 0.9912\n",
            "Epoch 58/100\n",
            "10000/10000 [==============================] - 6s 599us/step - loss: 0.0167 - acc: 0.9929 - val_loss: 0.0186 - val_acc: 0.9915\n",
            "Epoch 59/100\n",
            "10000/10000 [==============================] - 6s 600us/step - loss: 0.0165 - acc: 0.9929 - val_loss: 0.0187 - val_acc: 0.9911\n",
            "Epoch 60/100\n",
            "10000/10000 [==============================] - 6s 596us/step - loss: 0.0165 - acc: 0.9930 - val_loss: 0.0205 - val_acc: 0.9904\n",
            "Epoch 61/100\n",
            "10000/10000 [==============================] - 6s 590us/step - loss: 0.0165 - acc: 0.9929 - val_loss: 0.0217 - val_acc: 0.9906\n",
            "Epoch 62/100\n",
            "10000/10000 [==============================] - 6s 599us/step - loss: 0.0166 - acc: 0.9928 - val_loss: 0.0188 - val_acc: 0.9917\n",
            "Epoch 63/100\n",
            "10000/10000 [==============================] - 6s 598us/step - loss: 0.0165 - acc: 0.9928 - val_loss: 0.0190 - val_acc: 0.9916\n",
            "Epoch 64/100\n",
            "10000/10000 [==============================] - 6s 602us/step - loss: 0.0166 - acc: 0.9929 - val_loss: 0.0190 - val_acc: 0.9911\n",
            "Epoch 65/100\n",
            "10000/10000 [==============================] - 6s 594us/step - loss: 0.0163 - acc: 0.9930 - val_loss: 0.0191 - val_acc: 0.9912\n",
            "Epoch 66/100\n",
            "10000/10000 [==============================] - 6s 605us/step - loss: 0.0161 - acc: 0.9931 - val_loss: 0.0192 - val_acc: 0.9914\n",
            "Epoch 67/100\n",
            "10000/10000 [==============================] - 6s 604us/step - loss: 0.0162 - acc: 0.9931 - val_loss: 0.0187 - val_acc: 0.9916\n",
            "Epoch 68/100\n",
            "10000/10000 [==============================] - 6s 618us/step - loss: 0.0159 - acc: 0.9932 - val_loss: 0.0234 - val_acc: 0.9903\n",
            "Epoch 69/100\n",
            "10000/10000 [==============================] - 6s 613us/step - loss: 0.0158 - acc: 0.9934 - val_loss: 0.0188 - val_acc: 0.9914\n",
            "Epoch 70/100\n",
            "10000/10000 [==============================] - 6s 603us/step - loss: 0.0158 - acc: 0.9932 - val_loss: 0.0191 - val_acc: 0.9912\n",
            "Epoch 71/100\n",
            "10000/10000 [==============================] - 6s 618us/step - loss: 0.0160 - acc: 0.9932 - val_loss: 0.0181 - val_acc: 0.9913\n",
            "Epoch 72/100\n",
            "10000/10000 [==============================] - 6s 600us/step - loss: 0.0156 - acc: 0.9933 - val_loss: 0.0196 - val_acc: 0.9912\n",
            "Epoch 73/100\n",
            "10000/10000 [==============================] - 6s 604us/step - loss: 0.0157 - acc: 0.9932 - val_loss: 0.0200 - val_acc: 0.9913\n",
            "Epoch 74/100\n",
            "10000/10000 [==============================] - 6s 604us/step - loss: 0.0156 - acc: 0.9932 - val_loss: 0.0231 - val_acc: 0.9895\n",
            "Epoch 75/100\n",
            "10000/10000 [==============================] - 6s 598us/step - loss: 0.0159 - acc: 0.9932 - val_loss: 0.0189 - val_acc: 0.9914\n",
            "Epoch 76/100\n",
            "10000/10000 [==============================] - 6s 598us/step - loss: 0.0155 - acc: 0.9933 - val_loss: 0.0183 - val_acc: 0.9917\n",
            "Epoch 77/100\n",
            "10000/10000 [==============================] - 6s 594us/step - loss: 0.0154 - acc: 0.9933 - val_loss: 0.0193 - val_acc: 0.9911\n",
            "Epoch 78/100\n",
            "10000/10000 [==============================] - 6s 600us/step - loss: 0.0155 - acc: 0.9933 - val_loss: 0.0199 - val_acc: 0.9906\n",
            "Epoch 79/100\n",
            "10000/10000 [==============================] - 6s 596us/step - loss: 0.0154 - acc: 0.9932 - val_loss: 0.0197 - val_acc: 0.9906\n",
            "Epoch 80/100\n",
            "10000/10000 [==============================] - 6s 603us/step - loss: 0.0156 - acc: 0.9933 - val_loss: 0.0202 - val_acc: 0.9906\n",
            "Epoch 81/100\n",
            "10000/10000 [==============================] - 6s 599us/step - loss: 0.0153 - acc: 0.9933 - val_loss: 0.0190 - val_acc: 0.9916\n",
            "Epoch 82/100\n",
            "10000/10000 [==============================] - 6s 603us/step - loss: 0.0153 - acc: 0.9934 - val_loss: 0.0188 - val_acc: 0.9917\n",
            "Epoch 83/100\n",
            "10000/10000 [==============================] - 6s 604us/step - loss: 0.0152 - acc: 0.9935 - val_loss: 0.0194 - val_acc: 0.9914\n",
            "Epoch 84/100\n",
            "10000/10000 [==============================] - 6s 607us/step - loss: 0.0151 - acc: 0.9935 - val_loss: 0.0198 - val_acc: 0.9916\n",
            "Epoch 85/100\n",
            "10000/10000 [==============================] - 6s 601us/step - loss: 0.0152 - acc: 0.9935 - val_loss: 0.0211 - val_acc: 0.9912\n",
            "Epoch 86/100\n",
            "10000/10000 [==============================] - 6s 600us/step - loss: 0.0151 - acc: 0.9935 - val_loss: 0.0199 - val_acc: 0.9914\n",
            "Epoch 87/100\n",
            "10000/10000 [==============================] - 6s 591us/step - loss: 0.0151 - acc: 0.9935 - val_loss: 0.0214 - val_acc: 0.9902\n",
            "Epoch 88/100\n",
            "10000/10000 [==============================] - 6s 600us/step - loss: 0.0151 - acc: 0.9935 - val_loss: 0.0188 - val_acc: 0.9915\n",
            "Epoch 89/100\n",
            "10000/10000 [==============================] - 6s 603us/step - loss: 0.0150 - acc: 0.9935 - val_loss: 0.0195 - val_acc: 0.9912\n",
            "Epoch 90/100\n",
            "10000/10000 [==============================] - 6s 603us/step - loss: 0.0151 - acc: 0.9936 - val_loss: 0.0195 - val_acc: 0.9911\n",
            "Epoch 91/100\n",
            "10000/10000 [==============================] - 6s 597us/step - loss: 0.0149 - acc: 0.9936 - val_loss: 0.0212 - val_acc: 0.9911\n",
            "Epoch 92/100\n",
            "10000/10000 [==============================] - 6s 600us/step - loss: 0.0148 - acc: 0.9936 - val_loss: 0.0241 - val_acc: 0.9902\n",
            "Epoch 93/100\n",
            "10000/10000 [==============================] - 6s 602us/step - loss: 0.0147 - acc: 0.9938 - val_loss: 0.0211 - val_acc: 0.9913\n",
            "Epoch 94/100\n",
            "10000/10000 [==============================] - 6s 591us/step - loss: 0.0147 - acc: 0.9938 - val_loss: 0.0196 - val_acc: 0.9915\n",
            "Epoch 95/100\n",
            "10000/10000 [==============================] - 6s 592us/step - loss: 0.0147 - acc: 0.9937 - val_loss: 0.0196 - val_acc: 0.9914\n",
            "Epoch 96/100\n",
            "10000/10000 [==============================] - 6s 590us/step - loss: 0.0146 - acc: 0.9940 - val_loss: 0.0194 - val_acc: 0.9915\n",
            "Epoch 97/100\n",
            "10000/10000 [==============================] - 6s 593us/step - loss: 0.0147 - acc: 0.9938 - val_loss: 0.0214 - val_acc: 0.9911\n",
            "Epoch 98/100\n",
            "10000/10000 [==============================] - 6s 606us/step - loss: 0.0144 - acc: 0.9938 - val_loss: 0.0209 - val_acc: 0.9909\n",
            "Epoch 99/100\n",
            "10000/10000 [==============================] - 6s 593us/step - loss: 0.0144 - acc: 0.9937 - val_loss: 0.0209 - val_acc: 0.9915\n",
            "Epoch 100/100\n",
            "10000/10000 [==============================] - 6s 603us/step - loss: 0.0147 - acc: 0.9936 - val_loss: 0.0200 - val_acc: 0.9911\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGg0_cH1adwb",
        "colab_type": "text"
      },
      "source": [
        "### Saving the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJ9dr85Aadwb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filename = 'chatbot_120_epochs.h5'\n",
        "model.save(filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhaE2Eg7adwe",
        "colab_type": "text"
      },
      "source": [
        "## Evaluating the Model\n",
        "\n",
        "### Plotting Out Training History"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XR-MXCJ7adwf",
        "colab_type": "code",
        "outputId": "ef451f58-ba3e-44be-fc35-deea37aa35d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nOzdeXhU1fnA8e+bnSyQlTVsyq4iaAA3\nBLcKigtorVpta2tRq6221Z9aq21prV1saxf3nbqLGyoKiKBWRAmyy74nIISEhISsM/P+/jg3MAkh\nmWCGgeT9PE8eZu655865M3ree8659xxRVYwxxphQRUW6AMYYY44sFjiMMcY0iwUOY4wxzWKBwxhj\nTLNY4DDGGNMsFjiMMcY0iwUOYxohIs+IyB9C3HejiJwd7jIZE2kWOIwxxjSLBQ5j2gARiYl0GUzr\nYYHDHPG8LqLbRGSJiOwRkSdFpJOIvCcipSLygYikBe1/oYgsF5FiEZkjIgOD0oaKyJdevpeBhHqf\nNU5EFnl554rI4BDLeL6ILBSR3SKyRUR+Wy/9NO94xV76D7zt7UTkbyKySURKROR/3rbRIpLXwPdw\ntvf6tyIyRUSeE5HdwA9EZLiIfOZ9xjYR+Y+IxAXlP0ZEZopIkYhsF5FfiUhnESkXkYyg/U4QkQIR\niQ3l3E3rY4HDtBaXAOcA/YALgPeAXwFZuP/OfwYgIv2AF4FbvLRpwNsiEudVom8C/wXSgVe94+Ll\nHQo8BVwHZACPAlNFJD6E8u0BvgekAucDN4jIxd5xe3rl/bdXpiHAIi/f/cCJwClemf4PCIT4nVwE\nTPE+83nAD/wcyAROBs4CfuKVIQX4AHgf6Ar0AWap6tfAHOCyoONeDbykqjUhlsO0MhY4TGvxb1Xd\nrqr5wCfA56q6UFUrgTeAod5+3wHeVdWZXsV3P9AOVzGfBMQCD6hqjapOAeYHfcZE4FFV/VxV/ar6\nLFDl5WuUqs5R1aWqGlDVJbjgNcpLvhL4QFVf9D63UFUXiUgU8EPgZlXN9z5zrqpWhfidfKaqb3qf\nWaGqC1R1nqr6VHUjLvDVlmEc8LWq/k1VK1W1VFU/99KeBa4CEJFo4ApccDVtlAUO01psD3pd0cD7\nZO91V2BTbYKqBoAtQDcvLV/rzvy5Keh1T+CXXldPsYgUA929fI0SkREiMtvr4ikBrsdd+eMdY10D\n2TJxXWUNpYViS70y9BORd0Tka6/76o8hlAHgLWCQiPTGtepKVPWLgyyTaQUscJi2ZisuAAAgIoKr\nNPOBbUA3b1utHkGvtwD3qmpq0F+iqr4Ywue+AEwFuqtqB+ARoPZztgBHN5BnJ1B5gLQ9QGLQeUTj\nurmC1Z/6+mFgJdBXVdvjuvKCy3BUQwX3Wm2v4FodV2OtjTbPAodpa14BzheRs7zB3V/iupvmAp8B\nPuBnIhIrIhOA4UF5Hweu91oPIiJJ3qB3SgifmwIUqWqliAzHdU/Veh44W0QuE5EYEckQkSFea+gp\n4O8i0lVEokXkZG9MZTWQ4H1+LPBroKmxlhRgN1AmIgOAG4LS3gG6iMgtIhIvIikiMiIofTLwA+BC\nLHC0eRY4TJuiqqtwV87/xl3RXwBcoKrVqloNTMBVkEW48ZDXg/LmAj8G/gPsAtZ6+4biJ8AkESkF\n7sEFsNrjbgbOwwWxItzA+PFe8q3AUtxYSxHwZyBKVUu8Yz6Bay3tAercZdWAW3EBqxQXBF8OKkMp\nrhvqAuBrYA1wRlD6p7hB+S9VNbj7zrRBYgs5GWNCISIfAi+o6hORLouJLAscxpgmicgwYCZujKY0\n0uUxkWVdVcaYRonIs7hnPG6xoGHAWhzGGGOayVocxhhjmqVNTHyWmZmpvXr1inQxjDHmiLJgwYKd\nqlr/+aC2ETh69epFbm5upIthjDFHFBFp8NbrsHZVicgYEVklImtF5I4G0nuKyCxxs5rOEZHsoLQ/\ni8gy7+87QdufEZEN3gyli0RkSDjPwRhjTF1hCxzeFAgPAmOBQcAVIjKo3m73A5NVdTAwCbjPy3s+\ncAJultARwK0i0j4o322qOsT7W4QxxphDJpwtjuHAWlVd7z2R+xJumudgg4APvdezg9IHAR97s3ju\nAZYAY8JYVmOMMSEK5xhHN+rOzpmHaz0EW4yb4uGfwHggxVswZjHwGxH5G24itzOAr4Ly3Ssi9wCz\ngDsammZaRCbipsGmR48e9ZOpqakhLy+PysrKgzu7I0RCQgLZ2dnExtqaO8aYlhHpwfFbgf94q519\njJtzx6+qM7wnVecCBbjJ5/xenjtxc+nEAY8Bt+O6uepQ1ce8dHJycvZ7WCUvL4+UlBR69epF3clQ\nWw9VpbCwkLy8PHr37h3p4hhjWolwdlXl46arrpXtbdtLVbeq6gRVHQrc5W0r9v691xvDOAc39fNq\nb/s2daqAp6k7e2nIKisrycjIaLVBA0BEyMjIaPWtKmPMoRXOwDEf6Csivb0lOS/HrUewl4hkequc\ngWtJPOVtj65d41jcms6DgRne+y7evwJcDCw72AK25qBRqy2cozHm0ApbV5Wq+kTkJmA6EA08parL\nRWQSkKuqU4HRwH0ioriuqhu97LHAJ16ltxu4SlV9XtrzIpKFa4Uswq2kZowxrVYgoMxZvYMtRRWc\n2DONgV3aEx0VuYvCsI5xqOo0YFq9bfcEvZ4CTGkgXyXuzqqGjnlmCxczIoqLi3nhhRf4yU9+0qx8\n5513Hi+88AKpqalhKpkx5lCp9gX4ZE0B7yzZxs6yKhJio0mIjaZLhwQGdWnPoK7t+Wrrbh6es45V\n2/fNL5kSH8NRHZOp9gWoqvETHSUcnZVMn47J9O+cwoje6XRsnxC2ckd6cLzNKi4u5qGHHtovcPh8\nPmJiDvyzTJs27YBpxpjmU1UKSqvYXFTOzrIqyqv9VNT4iYkSeqQn0TszibSkWL4uqSRvVwWFe6rp\n0C6W9MQ4UhNjaZ8QS3JCDNFRQmWNn+LyGgr3VLGzrJqdpVXsLKuiqLyaXXuq2VVegyrEeK2FzzcU\nsqu8htTEWHpmJFFQWkVljZ/pyyup9gX2lrFvx2T+ftnxDOuVzpebd/HFhiI2F5UTHxNNQmwUVb4A\nq3eUMnPFdvwB3ZvnlKMzuG7U0XRNbdei35kFjgi54447WLduHUOGDCE2NpaEhATS0tJYuXIlq1ev\n5uKLL2bLli1UVlZy8803M3HiRGDf9CllZWWMHTuW0047jblz59KtWzfeeust2rVr2f9AjDkYgYCy\nekcp8zcUUVbl5/jsDgzunkpy/P5Vzo7dlWzZVcHALikkxjVeJakquyt8fL27ksS4aFITY0mOj6Gk\nooYtRRXkF5eTmhhH347JZCTHEwgo23ZXsr6gjD1VPqKjooiJFraXVLIkv4SleSWs2VFKZU2g0c8N\nRVxMVJ3Kvk5adBRpSbGkJcYRJYI/oPgCAU7rm8XFQ7oysm8WcTH7hpxr/AHWF+xh+dYS0hLjGNUv\niygv2HRPT+SiId0a/JxqX4CVX+9m7rpC5q4r5JXcPH5yRp9vfG71tYlp1XNycrT+XFUrVqxg4MCB\nAPzu7eV8tXV3i37moK7t+c0FxxwwfePGjYwbN45ly5YxZ84czj//fJYtW7b3ttmioiLS09OpqKhg\n2LBhfPTRR2RkZNQJHH369CE3N5chQ4Zw2WWXceGFF3LVVVft91nB52pMS1BVtu92V8eJcdHEx0az\nubCczzcUMm99EfM3FlFSUVMnjwj0ykiiW2o7uqa6bpT5G3exYecewF2FH9O1PYOzU0lJiCEhNpro\nKGFbSQVbiyvJ31VBfnEFZVW+OseNjpK9V9nB0hJjqajxHzAotE+IYXB2Kv07p9AzI5Hu6Yl0Skkg\nKT6adrHRVPkCbCosZ8POMor21NAlNYHstHZkJsezu6KGoj3VFJfXUFrlo7SyhooaP+0TYklPiiMt\nMZbM5Hj3lxJPUlx0RG5UqfEHiI0++HugRGSBqubU324tjsPE8OHD6zxr8a9//Ys33ngDgC1btrBm\nzRoyMjLq5OnduzdDhripuk488UQ2btx4yMprDn81/oDrdqn2e1fk5WwuKmdHaRUpCTGkJ8WRmRzP\n8dkdDtgfvqfKxxcbitiyq5yC0iq2765kfcEeVm0vpbTS12CeXhmJnHtMJ0b0zmB473RSEmJYtKWY\nRVuKWb29lK3FlcxZVUC1P0BOzzSuHN6DHhmJLMkrJnfjLt5clE9FtR+fFww6tIulW2o7emQkcvLR\nGWSntaNT+wQqa/zsKneVd1piHN3T29EtNZGi8mrW7ihj7Y4yEuOiOSoriaMyk+nQLhZ/QKkJBMhI\niqNHemKTlXn39ERO65v5zX6ICPomQaMxFjig0ZbBoZKUlLT39Zw5c/jggw/47LPPSExMZPTo0Q0+\nixEfH7/3dXR0NBUVFYekrCZ8NuzcQ5XPT/e0RJKCunWqfH4EqdOdAe7Kv8oXoKomQKXPz6bCcmav\n2sGcVQWs2NZwKzomSvZWyrV6ZSRyYs90MpPjSIiNJkqE+RuL+GJDEdV+d8UeJZCRHE/vjCQuGtKV\nfp1SSI6PoaLGBaeslHhG9M6gc4f9g9Do/h0Z3b9jo+d+7jGd67z3+QP4AkpCbHSj+Royqt9+M4Gb\nFmSBI0JSUlIoLW14Fc6SkhLS0tJITExk5cqVzJs37xCXzoRDSXkN8zcWMXddIV9u3kWfjsmMPbYz\np/bJJHfjLh79eB2frNm5d//0pDhiooTdlTV7u1uS4qJJTYwjOkoorayhtNK3XxCIiRJO7JnGz87s\nQ/t2sSTGxZCSEEP39ER6pCeSlhhLlS/ArvJqtpVU8uWmXXy+oYiPVhdQWllDlddP36djMt8/pSej\n+3ekX6cU0pPiDuktoDHRUcQ0P2aYQ8ACR4RkZGRw6qmncuyxx9KuXTs6deq0N23MmDE88sgjDBw4\nkP79+3PSSSdFsKQmWI0/wNL8EuatL2RpXgnbd1eyo7SKkgrXXZKRHEdqu1h8AdcSqKzxU7SnmsKy\naipq3Kw58TFRHNetA9OXf82UBXnERgs1fiUzOZ7bzu1Pj/REtuwqZ0tRBYGA0iExlvYJMajCrvIa\niiuq8fmV9u1iaJ8QS1J8jHcbZxSZyfGcfHQG7RMan5vM3fLZji4d2nFCjzSuHXnU3rRAQKn2Bw7q\nSt+0DTY43ga0pXNtCbUDv0vzS1iaX8LGnXso3FNFYVk1m4vKKa92AaB3ZhJdUxPomJJA+4QYiitq\nKCyrpriimpioKOJjooiPjSYjKY6MpDgyU+IZ0j2VoT1SiY+JptoXYO66ncxZVcCAzilcPLSbVdbm\nsGKD48aEIG9XObe+uph564sA16+fnZZIVko8PdITOemoDEb0Tmd473QykuObOFrj4mKiQur7N+Zw\nY4HDGM+bC/O5+81lBFT5vzH9Gd4rnUFd2zf5bEGr4auG6Fh33+zhLuCHqBZonQX8gEBUWBdDbXXa\nyP8RxhxYebWPu95YxhsL8zmxZxr/uGwIPTISD10BClZDh2yIa8HPrN4DJXmQ1T+0/b9eBo+fCeqH\nxExI6Qyn3wYDxzWeTxU2z4Pcp6D7cBj+429e9sbkLYDPH4av3oJTb4EzftX8QLf+I1j8Iuz4CgpW\nQVwy5PzQ/SV3hE1zYdlrUFMO50xy30UodqyEzL4tE9Dq81VD4VqIT4HU7gfez18DRetD/90PkgUO\n06atKyjjhucWsHZHGT8/ux83nnE0MWG6930/ZTtgxt2w5CXodCxc+bILILUqiiEmAWKbMedQTaWr\nxP/3d9hTACN/CWfc1XRlNuPXLnCdeI3Ll5cLL18F3/oDnHxj3cpZ1VVO62fDgmfh6yVu+8p34bhv\nQ7ugedSWToGNn8CJP4CuQ0M/j/oqS+CF78DmzyC+PWQPg4//AlWlMOa+0INHST68eAXExEPXIZDz\nI3cuH//VfWft0mHPDohNdOe5fg5c+jT0OhUqd8OiF9z5nnd/3UC/4h14+bvQ9QQ4/2/Q7YTmnZ8q\nbFsMy6bA8jehvBCSMiEpC6rLoXANBHwQFeuC5ak37/+b+qpdGdbMgJN+4oJedHgWcLPAYdoMVWVj\noXsIbteeavKLK3h4zjriYqKY/MMRh/ZBr/lPwge/hZoKV1kvew2eONsFj+RO8MnfYMEzkJgBFz0I\nfc6qm99XDV8vhfxc2LXRtTBqymHjp1C6FXqPgvZd3XHycuHSp1xF1JC1H7ggcO59cLI3d1p1Obxx\nHcy4C3ZtgL7nuiv07ctd5V3iLe6ZNRAu+Cd0HARPnuPKfNotLq28CN75BVSVuO3dR8BRo92V844V\nULbdtW6SsiAuyVWWewpAouBHMyE56FmM5W+6zz1nkmsZxCXD9F/BvIegusyVIZQr/el3ulbVxNmQ\n1mvf9qL18MUT7rsbeAH0GwO7NsErV8OzF7hta2dBtXcLfceBcMpP3WtV9z2ndIHd+a7lduL3YdDF\n7ntJ7ugCW/UeqNgFKV3rdo0FAvD8JbDuQ4iKgT5nQ0Yf2LPTBbGkjtB/rPvMle/ArN/B6vfh4och\n42h3DH8NTLnGBY0+Z7vvJf9L+PYz0L5L099LM9ldVW1AWzrXvfw+iHbXRZ+u3cm7S7fx8eoC8nbV\nfUjyhB6p/OfKE1puEriyAnfl2r6r+x+903GQ0qnuPuvnwOSLXOV+/t8hsw9s/wqe/zZUFLmKKFAD\nx1/uKv2ClTDsWlcRbfwENnwM+QvAX+2OF5fsKt64JEjtCSN/Ab1Pd2kLn4N3f+kq6O9P3VfR1Ar4\n4ZHTXAC78QuIiQtKC8AH98Dcf+/bltIVug9zx+89ylVwtVf7z14IO9fALUvcle7M38Cn/4Rr3oOt\nC+GLR12Q69ADOg1yXUDlRa6CrC5zQTKhA3z1Joz9C4y4bt/nPv9t16108+J9n6cKs//oWh4DxsGE\nx9x3cCBrPnAV9Jm/dt1woajcDVNvglXvwzEXuzLN+r0L2rcscZ+34RN4dpz7LY+7FOb8CT5/1AUo\ngIRUV7HXuKlVOOlGGPPHfZ+x5FV4/VoYdTuMuB4S0w9cHlVY+iq8e6sLYr1GwrGXwIaP3MXHmD/D\nSde7lt7Un7ryXf0mdD42tPOt50B3VVngiJCDnVYd4IEHHmDixIkkJobWJx7pcz3kCtfBk+dQ1e8C\nbq/4Pm8u3kZSXDSn9Mnk9H5ZDOycQlpS3N7ZTfebdkLVVYAbPnKVdNkO12fccZDrw07u6K6SEzP3\nBieg7pVjLYmCS56EYyfs2+exUa4b6qb5dbuhSr+GN653LY7Rt0P6Ua5Cn/V7mPfgvuN1GQI9T3Hd\nNdk50L5b4101WxfBcxMgph1cMw3Seu5L+3Kyq2C+/QwcM77h/Js/BxSyBtTthqpv9Qx44dsw4Qno\ndRr8a6i7Ur/k8X3n7qtseiznoVNcX/6Pprv3VaXwl6Ng2I/rVri15j0C79/hup6ueHn/QA3ue3zo\nJNfVc8OnrquqOQKBfa2ELV+41tU5k1yX0XOXuG6mW5ZCrHcBsqcQti9zLaudq932pCwX8Fe87VpU\n3Ye5rsX/5Lhg8eM5oQ/S794KuU+7rq2i9W7b2b/b19oD99mz/wjjH2k8oDbCAsdhFjiCJzlsrtqJ\nDjMzQ+taifS5HlK+avSpb6HblhGlNTzrP5ddp/+eG87oQ3wojyGrwpQfwvLX3fsO3d24Q8FK180Q\nrF06fPtp1/0C8Om/YObdMO4BGHih69r54Leu4rj+E9c1svgl1wU04QkY/O3Qzyv/S9e10+Pkxivv\nA/l6KTwzzl3RX/Oeq6i2fA6vX+cGW38085vfTRUIwEMjXCXZ7UQXlG6a7wJgc3z8V/jwD/Dz5e67\nX/a664a55j0XMBuychq89iPXahkwznV57SmA6DgX6PfshDXT4Xtv7fu9von/ToBti+DyF+Gpb8GZ\nd8Pptzadr3K3C2Dx7eG6j12X0ge/ge9NhaNGNb8ctWMjZduh37nNz9+EiDzHISJjgH/iVgB8QlX/\nVC+9J2652CygCLfSX56X9mfgfG/X36vqy9723sBLQAawALhaVavDeR7hEDyt+jnnnEPHjh155ZVX\nqKqqYvz48fzud79jz549XHbZZeTl5eH3+7n77rvZvn07W7du5YwzziAzM5PZs2dH+lQiTlXJL65g\nWX4JCbN/x+jChVxffQvnJG/g+9VvAQMg+nfuf9ryQkjtceD+8Ln/ckHj1Jvd2ENaL1ehqrqWR9E6\nr++5AOY/4a42xz0AnY6BWZPcFfaJP3B5eo90YwuPnAavXQtXv+FaD12Huu6F5mjuYGt9nY+Dq1+H\nyRe78lSXua6u2EQ3ttESt+BGRblB2XdugW1L3FhEc4MGwDETXOBY/oYbR1j5rgsI3UccOM+A81xr\n6pXvue652oHlyhIXwPcUwNCrWiZogBugfuIseOEy11U47Eeh5UtoD+P+4fLNvBsWvejGjw4maID7\n3boOObi830DYWhwiEg2sBs4B8nBrkF+hql8F7fMq8I6qPisiZwLXqOrVInI+cAswFogH5gBnqepu\nEXkFeF1VXxKRR4DFqvpwY2VpssXx3h3uiqwldT4Oxv7pgMnBLY4ZM2YwZcoUHn30UVSVCy+8kP/7\nv/+joKCA999/n8cfd039kpISOnTo0LZbHGU74PNH2T1kIm+tqeTdJVtZvnU3pZU+RkYt4b9xf+LT\n1AvYdeZfOGdgR+Jn3O4q+Oi4fWMC3XJcJZ7Qvu6xN3wCky90rYVvP9N0ZVq5G179vuuaSkh1Fcj1\nn+zfR73sNdeKyewPO1fBD951XTmRsPlz+OR+yOznxih6nuy6hVpKTQX8fZD79+ZFod/KWt+jo1y3\n3A+nw1+PhkEXupsEmqLa8O92oO3fxHOXwtqZcPJNcO69zcs75Ueum0mi4IbPoOOAli1bC4lEi2M4\nsFZV13sFeAm4CPgqaJ9BwC+817OBN4O2f+ytM+4TkSXAGC/QnAlc6e33LPBboNHAcbibMWMGM2bM\nYOhQd7tiWVkZa9asYeTIkfzyl7/k9ttvZ9y4cYwcOTLCJY2cQEBZv20nHV69lKzixcz96GPurr6Z\nfp1SuGhIV05Iq+SCeU+gSQM4deJj+/rRx/7VDeCWbnNXoP4amH2vu+K76rV9fb+lX7vKPf1ouPDf\noVUyCe3hyldg2q3uNs0rXmx4YPPYS2DdbFj4X+g3NnJBA6DHCPjuq+E7fmw7N0hdU3HwQQPcmNDM\ne2DhZKjaDQMuCC3fgX63cDzUePZv3Z1SJ9/U/Lxj/+yeFxl00WEbNBoTzsDRDdgS9D4PqN/WXAxM\nwHVnjQdSRCTD2/4bEfkbkAicgQs4GUCxF1Bqj9ngUlgiMhGYCNCjR4/GS9pIy+BQUFXuvPNOrrvu\nuv3SvvzyS6ZNm8avf/1rzjrrLO65554GjtA6VVT7+Wh1AdOXf82cldv5te/fXBK9mI8lhzFRX/DJ\n2EKyTz8f8VXC0+eBr8KNOQQPvkZFwUk31D1wWi/XH/7i5TDqDvcw2fLXXSXw/an7t0QaEx3rbgU9\n977GB33H/tn1tZ94TbO+gyNS33O++TGOGe8Cx8zfQGzSwXflhFPnY+GH7x1c3qRM1yKLjmt638NQ\npJ/juBX4j4j8APgYyAf8qjpDRIYBc4EC4DPA35wDq+pjwGPguqpastAtIXha9XPPPZe7776b7373\nuyQnJ5Ofn09sbCw+n4/09HSuuuoqUlNTeeKJJ+rkDbWr6kj0au4W7nlrORU1flITY/l91odcsOMT\ndg2/lZHn3gnPnEf3z+6GIWe7vuKtC+HyF9xtnk05doJrebxxnbtrKiYB+n7LPejW8SC79Jq6Uygu\nCc5qO0H/G0vtAdnDIe8L13UY20K3Sx9Omntn12EknIEjHwh+Nj7b27aXqm7FtTgQkWTgElUt9tLu\nBe710l7AjZcUAqkiEuO1OvY75pEieFr1sWPHcuWVV3LyyScDkJyczHPPPcfatWu57bbbiIqKIjY2\nlocfdj1yEydOZMyYMXTt2rVVDo6/PH8zt7+2lJOPyuCno3szYvsLRM96FI4ZT9rYX7tuh4sfdoO8\nj58JZV/DWb9xA6ShOv477u6kyhL3sFdzWhnm0Dh2ggscA5qY9sQccuEcHI/BVfZn4Sr3+cCVqro8\naJ9MoEhVAyJyL661cY83sJ6qqoUiMhh4ARiiqj5vnOO1oMHxJar6UGNlORxvxz2UjqRzfemLzdzx\n+lJG9cvisQsyiX/7Rtg8192tNP6xulf2XzzuxhcGfwfGP3pkTM5nQldVBvMfhxE3NG/aFdNiDvng\nuFfJ3wRMx92O+5SqLheRSUCuqk4FRgP3iYjiuqpu9LLHAp94D2btxt2mWzuucTvwkoj8AVgIPBmu\nczCHQFWpe6AKZe66Qj7+aBkPdCrignbFRD8+x911cvEj7inq+oFh2LXuNthuORY0WqP4ZDjt55Eu\nhWlAWMc4VHUaMK3etnuCXk8BpjSQrxJ3Z1VDx1yPu2PLtAbv/NxNoQCcApwSB7o7Cok5Cgac7x6s\nOtBsoCIHfiDMGBM2kR4cjyhV3X+6iVbmsJ4ZYOdaWPYa1cdfzc9XH0tFtZ/7rzyJ9B6DWudgqDGt\nRJsNHAkJCRQWFpKRkdFqg4eqUlhYSELCYdo//L9/oNFx/LrkIt4vqeGFa0eQflRGpEtljGlCmw0c\n2dnZ5OXlUVBQEOmihFVCQgLZ2dlN73io7dqELnmJuWkX88rKau4cO4ARFjSMOSK02cARGxtL7969\nI12MNqmyxs+6V39Pv4By29ZR/PDU3kw8/SDmNDLGRESbDRzm0Cur8vHC55t48+MFvFHzJp+mnMuz\nN4ynb6cWnCvJGBN2FjjMITFlQR6/f3spQ6sX8EDyO8RFBRj9wz9CugUNY440FjhM2G3evpNlb/6N\n9+Km0zUuH+I6w7l/h3TrKjTmSGSBw4RP5W50/pN0mP0Av40upjprKJw6yc09FHNkTu5mjLHAYcIl\nEIDJFyJbF7LIP5jSYX9l3AXftie8jWkFLHCY8Fg2BbYu5N6YG/kkdQzvnH+aBQ1jWgkLHKbl+arQ\nD3/P1oS+PFF8Mq9edSwx0VGRLpUxpoXY/82mxRXMfggp3sztuy/lR6cdTU6vBlbFM8YcsazFYVrU\nK/9bxjn/+xvz5Dguv/x7jMWpmKoAACAASURBVBvcNdJFMsa0MAscpsWs3byF6um/IS26lP5X/Z2T\n+ljQMKY1ssBhvrlFL6ALn6P3ps/oEx2g6tgrSOtjM98b01pZ4DDfzNz/wIy72NO+D0/7LqT3KZcw\nbowt9WlMaxbWwXERGSMiq0RkrYjc0UB6TxGZJSJLRGSOiGQHpf1FRJaLyAoR+Zd4c597+60SkUXe\nX8dwnoNpxMLnYMZd+AdeyAW+PzM1/Yece+44iLJ7LoxpzcL2f7i3bviDwFjcan5XiEj9Vf3uByar\n6mBgEnCfl/cU4FRgMHAsMAwYFZTvu6o6xPvbEa5zMI1Y8TZM/SkcdQZPdvwVG4qquOeCQcTabbfG\ntHrh/L98OLBWVderajXwEnBRvX0GAR96r2cHpSuQAMQB8bg1yLeHsaymOSp3w+sToesJ7L74af49\nZzNnD+zIyL5ZkS6ZMeYQCGfg6AZsCXqf520LthiY4L0eD6SISIaqfoYLJNu8v+mquiIo39NeN9Xd\ncoDl+0Rkoojkikhua1+s6ZBbMwNqyuFbf+C5LwsprfLx83P6RbpUxphDJNL9CrcCo0RkIa4rKh/w\ni0gfYCCQjQs2Z4rISC/Pd1X1OGCk93d1QwdW1cdUNUdVc7Ky7Eq4Ra2YCkkdqex8Ik/9byOj+mVx\nTNcOkS6VMeYQCWfgyAe6B73P9rbtpapbVXWCqg4F7vK2FeNaH/NUtUxVy4D3gJO99Hzv31LgBVyX\nmDlUaipgzUwYOI4pC7exs6yK60cdHelSGWMOoXAGjvlAXxHpLSJxwOXA1OAdRCRTRGrLcCfwlPd6\nM64lEiMisbjWyArvfaaXNxYYBywL4zmY+tbOgppy/P3H8djH6xnSPZWTjrIpRYxpS8IWOFTVB9wE\nTAdWAK+o6nIRmSQiF3q7jQZWichqoBNwr7d9CrAOWIobB1msqm/jBsqni8gSYBGuBfN4uM7BNGDF\n25CQyntlfdhcVM4No4/mAMNMxphWSlQ10mUIu5ycHM3NzY10MY58vmq4vw/+fudx/uYrqfEHmPnz\nUURFWeAwpjUSkQWqmlN/e6QHx82RZOPHUFnC4zuPZeXXpdz6rf4WNIxpg2zKERMy/eptqqPa8Y/1\n3fjVeQMYe1yXSBfJGBMBFjhMaPw+ypdO5cOa4/nBqAFMPN3upDKmrbKuKhOSvP89T1JNEQW9LuSO\nMQMiXRxjTARZ4DBNCwSImft31mg2l1x+rd1FZUwbZ4HDNKlk0Rt0rtrIwl7X0iEpPtLFMcZEmAUO\n0zhVqmb9mfWBzuSc98NIl8YYcxiwwGEaVb1yOh33rGJO1nc5qpPNR2WMsbuqTGNU2T3jj1RqJv3P\nuTbSpTHGHCasxWEOSDfPI3PXYt5sdymn9LdnNowxjrU4zAHtmPVv2mkinUddY3dSGWP2shaHaZC/\nZBsZm9/n/dizuWi4LdJkjNnHAodp0Mp3/00MfrLOvNHWETfG1GE1gtlPZWUFnVY/T25sDqNPHhHp\n4hhjDjMWOMx+Pn37GTIpJnHk9Ta2YYzZjwUOU0dJRQ1py59hR0wXBp12SaSLY4w5DIU1cIjIGBFZ\nJSJrReSOBtJ7isgsEVkiInNEJDso7S8islxEVojIv8S79BWRE0VkqXfMvdvNNxTww5qZbH/iMk5g\nJYGcayHKriuMMfsLW80gItHAg8BYYBBwhYgMqrfb/cBkVR0MTALu8/KeApwKDAaOBYbh1h0HeBj4\nMdDX+xsTrnNoM3ZthH8OgecvJXPnfGamXkbns26KdKmMMYepcF5SDgfWqup6Va0GXgIuqrfPIOBD\n7/XsoHQFEoA43DrjscB2EekCtFfVeerWvJ0MXBzGc2gbvvwv7M7jnf5/ZETVg2R/528QmxDpUhlj\nDlPhDBzdgC1B7/O8bcEWAxO81+OBFBHJUNXPcIFkm/c3XVVXePnzmjimaa6V7+Drfgp3ruzD2cdm\nM7BL+0iXyBhzGIt0J/atwCgRWYjrisoH/CLSBxgIZOMCw5kiMrI5BxaRiSKSKyK5BQUFLV3u1mPn\nGihYycfRIyit8nHz2X0jXSJjzGEunIEjH+ge9D7b27aXqm5V1QmqOhS4y9tWjGt9zFPVMlUtA94D\nTvbyZzd2zKBjP6aqOaqak5WV1VLn1PqseBuAP64/mvOO68yAztbaMMY0LpyBYz7QV0R6i0gccDkw\nNXgHEckUkdoy3Ak85b3ejGuJxIhILK41skJVtwG7ReQk726q7wFvhfEcWr+V71DQ/hjWVqVy4xl9\nIl0aY8wRIGyBQ1V9wE3AdGAF8IqqLheRSSJyobfbaGCViKwGOgH3etunAOuApbhxkMWq+raX9hPg\nCWCtt8974TqHVq8kH/IXMCMwjAGdUzimq623YYxpWlhnx1XVacC0etvuCXo9BRck6ufzA9cd4Ji5\nuFt0zTe18l0Anio8hgnf6hrhwhhjjhSRHhw3kbTybXYl9maddmPcYFtvwxgTGgscbVV5EWz8lJk6\njOO6daBnRlKkS2SMOUJY4Gir1swE9fPf4sFccLy1NowxoQspcIjI6yJyftAdUOZIt+l/VMaksEx7\ncf5gG98wxoQu1EDwEHAlsEZE/iQi/cNYJnMobPqMRQxgaI90uqW2i3RpjDFHkJACh6p+oKrfBU4A\nNgIfiMhcEbnGe87CHEnKdkDhGmZX9OGC4621YYxpnpC7nkQkA/gBcC2wEPgnLpDMDEvJTPhs/gyA\nLwIDOO84G98wxjRPSM9xiMgbQH/gv8AF3hPcAC+LSG64CmfCZNNnVBFPVLchdGpvs+AaY5on1AcA\n/6WqsxtKUNWcFiyPOQRqNvyPBf6jOWOQTSxsjGm+ULuqBolIau0bEUkTkZ+EqUwmnCp3E71jOfN1\nAGcN7BTp0hhjjkChBo4fe7PWAqCqu3Cr8JkjzZYviCLAunbHM6BzSqRLY4w5AoXaVRUtIuKtule7\nLGxc+IplwqVmw6eg0XQadBq2XLsx5mCEGjjexw2EP+q9v87bZo4wZas/YpP2YtSxvSJdFGPMESrU\nwHE7Lljc4L2fiZva3BxJaipJKVzCIjmXK3unR7o0xpgjVEiBQ1UDwMPenzlCBfIWEKM1VHY7ibgY\nmz3GGHNwQn2Ooy9wHzAI2Hvjv6oeFaZymTDYvuxDugDdjz8z0kUxxhzBQr3sfBrX2vABZwCTgefC\nVSgTHqWrPmKVdufU4/pGuijGmCNYqIGjnarOAkRVN6nqb4Hzm8okImNEZJWIrBWROxpI7ykis0Rk\niYjMEZFsb/sZIrIo6K9SRC720p4RkQ1BaUNCP922a9OOYrqVLqE4axipiXZDnDHm4IUaOKq8KdXX\niMhNIjIeSG4sg3fL7oPAWFwX1xUiMqjebvcDk1V1MDAJ1x2Gqs5W1SGqOgQ4EygHZgTlu602XVUX\nhXgObdob771HklQx4KSxkS6KMeYIF2rguBlIBH4GnAhcBXy/iTzDgbWqul5Vq4GXgIvq7TMI+NB7\nPbuBdIBLgfdUtTzEspp61u4oo2LNRwB06D8qwqUxxhzpmgwcXsvhO6papqp5qnqNql6iqvOayNoN\n2BL0Ps/bFmwxMMF7PR5I8WbhDXY58GK9bfd63Vv/EJH4A5R7oojkikhuQUFBE0Vt3R74YDUnRa/C\nn94HUmyaEWPMN9Nk4FBVP3BamD7/VmCUiCwERgH5gL82UUS6AMcB04Py3AkMAIYB6bhnTPajqo+p\nao6q5mRlZYWp+Ie/Fdt2M21JPifHrCa616mRLo4xphUI9QHAhSIyFXgV2FO7UVVfbyRPPtA96H22\nt20vVd2K1+IQkWTgkuA5sYDLgDdUtSYoT+2U7lUi8jQu+LRJPn8AESE6quGpQ1SVSW9/xQkJW0nw\nl0GvcMV/Y0xbEmrgSAAKcQPVtRRoLHDMB/qKSG9cwLgct/zsXiKSCRR5DxjeCTxV7xhXeNuD83RR\n1W3iJlq6GFgW4jkcEXz+AAu3FPPFhiJO6JHGyUfX77lzKqr9XP7YZ5RX+3n+2hF0bGBdjSkL8vhs\nfSFThu6EFUDPU8JcemNMWxDqk+PXNPfAquoTkZtw3UzRwFOqulxEJgG5qjoVGA3cJyIKfAzcWJtf\nRHrhWiwf1Tv08yKSBQiwCLi+uWX7JvwBJe/rAmIKv6JbB2+t7qRMyDgacFf5IgIBP2xbBH4fAEXl\n1STGRZMQEw3RsdDleHwqfL27kpXbSvlq226W5pcwb30hpZW+vZ83fmg3fj06g4zUVIhP2fsZv3pj\nKUvyS4iPieLyx+fx2hg/aQkCR7vYXlhWxb3TVpDTM40TdQWk9oQO2YfwmzLGtFahPjn+NK6FUYeq\n/rCxfKo6DZhWb9s9Qa+nAFMOkHcj+w+mo6oReez5vaXbePiDZZxS9CY/jnqLDCmtk746fTR/rZrA\nvLKO/GfIFk7PfxzZuXpvev2ZodZJd+6vvoT3/MMAQQR6ZSQxbnAXTu+bxYm90nhr9mek5d5D6oqP\nqYxJQU79GfGn3MAzuQW8sTCfX5zTj5Gdqtn+6i9Ie3UeGhWLTJwNnY/j3ndXsKfKxx/HH4tMngt9\nzw3/l2SMaRPEmym98Z1ELgl6m4C7A2qrqv4sXAVrSTk5OZqbexAr3H76L9juesLmbyik5+4FdJRd\nfJ11Csu7XspH6/ewoXAPQ2UtP455lySpZGd0Rzr6t5MX05PdJ97I04vL2b67kjHHdCalXQwFZdVQ\nso1xpS/TsXozRSkD0I4DaJ8QS2x00L0K1Xtg9XQCEsWMdmOJKdnE2dELKYtO5YPqY+jcoR0jenZA\nVr9PIODjUd84LuUDSqPT+HuvR3jnqyJ+emYffjlE4aERcNGDMPSqFvpGjTFtgYgsaGiV11C7ql6r\nd7AXgf+1UNkOXztXwZbPAehVUcWW2J50vOp5Ovc6lc7AWcDq7aWs21FGoOsfiVr4MFmb5/Fp6s1M\nXNibPR8pXTok8I9rh3DSUfXGKvx3wNJXSJ/3MBQ19AyjwAlXE3X6bYxp35WFm3fxlxnvMHzT4wyP\nWUfnmARkK9DnLKK+9XtGV6bz0ZyXuXTVreRsepwNXa/hxlG9YPbv3OFsfMMY00JCanHsl0mkP/Cu\nqvZp+SK1vINucQT5/lNfUFxRw1s3hnZL64ade3h3yVa+O6InaUktN8XH1uIKkuJi6JAY2/AOb94I\ni1+Ac34PX052wa//eXD5C2ALNxljmuEbtThEpJS6Yxxfc4DnJ1qryho/8c2Yirx3ZhI3ndnykwl2\nTW3X+A5j7oMNH8GMuyD9aBcw+p9nQcMY02JC7apq84tTV/kCpCSEevdyBCW0hytfga0L4bhvQ4xN\naGiMaVkhXUKLyHgR6RD0PrV2ttq2osoXID4mOtLFCE2nQTD0uxY0jDFhEWrfy29UtaT2jfd092/C\nU6TDU5XPT3ysrZpnjDGh1oQN7XcE9Nu0nKqagHt4zxhj2rhQA0euiPxdRI72/v4OLAhnwQ431uIw\nxhgn1Jrwp0A18DJuXY1KgqYHaQuqagLNuqvKGGNaq1DvqtoD7Lf0a1tyRA2OG2NMGIV6V9VMEUkN\nep8mItMby9OaBAJKtd9aHMYYA6F3VWUGr5OhqruAjuEp0uGn2h8AICHWWhzGGBNq4AiISI/aN96U\n582fq+QIVVnjFiW0FocxxoR+S+1dwP9E5CPcOhgjgYlhK9VhpsrnWhx2V5UxxoQ+OP6+iOTggsVC\n4E2gIpwFO5xU1XiBwwbHjTEm5MHxa4FZwC9xa3z/F/htCPnGiMgqEVkrIvvdlSUiPUVklogsEZE5\nIpLtbT9DRBYF/VXWTnEiIr1F5HPvmC+LSNjn1ajyWVeVMcbUCrUmvBkYBmxS1TOAoUBxYxlEJBp4\nEBgLDAKuEJFB9Xa7H5isqoOBScB9AKo6W1WHqOoQ3Drn5cAML8+fgX94U7rvAn4U4jkctNquKhsc\nN8aY0ANHpapWAohIvKquBPo3kWc4sFZV16tqNe7BwYvq7TMI+NB7PbuBdIBLgfdUtVxEBBdIapeb\nfRYI+2SLNjhujDH7hFoT5nnPcbwJzBSRt4BNTeTpBmwJPgb7ryG+GJjgvR4PpIhIvaXyuBx40Xud\nARSrqq+RYwIgIhNFJFdEcgsKCpooauP2Do5b4DDGmNACh6qOV9ViVf0tcDfwJC1zpX8rMEpEFgKj\ngHzAX5soIl2A44BmP2yoqo+pao6q5mRlZX2jQu4d47CuKmOMaf4Mt6r6UYi75gPdg95ne9uCj7UV\nr8UhIsnAJcEPGgKXAW+oao33vhBIFZEYr9Wx3zHDofauqgS7HdcYY0LuqjoY84G+3l1Qcbgup6nB\nO4hIpojUluFO4Kl6x7iCfd1UqFsgfTZu3APg+8BbYSh7Hfu6qqzFYYwxYQscXovgJlw30wrgFVVd\nLiKTRORCb7fRwCoRWQ10Au6tze89nd4dqN/CuR34hYisxY15PBmuc6hlg+PGGLNPWBdjUtVpwLR6\n2+4Jej2FfXdI1c+7kQYGvlV1Pe6OrUPGBseNMWYfqwlDYIPjxhizjwWOEOwdHLcWhzHGWOAIRZUv\nQHSUEBNtX5cxxlhNGILKGr+NbxhjjMdqwxC4ZWPtqzLGGLDAEZIqn9+e4TDGGI8FjhBU+QL21Lgx\nxnisNgxBVU3AWhzGGOOxwBGCSp/flo01xhiP1YYhcC0O+6qMMQYscITEBseNMWYfCxwhsMFxY4zZ\nx2rDELjnOKzFYYwxYIEjJPbkuDHG7GO1YQiqfAG7q8oYYzxWG4agqsYGx40xplZYA4eIjBGRVSKy\nVkTuaCC9p4jMEpElIjJHRLKD0nqIyAwRWSEiX3krAiIiz4jIBhFZ5P0NCec5gLU4jDEmWNhqQxGJ\nBh4ExgKDgCtEZFC93e4HJqvqYGAScF9Q2mTgr6o6ELfi346gtNtUdYj3tyhc5wCgqjY4bowxQcJ5\nGT0cWKuq61W1GngJuKjePoOAD73Xs2vTvQATo6ozAVS1TFXLw1jWA7JlY40xpq5w1obdgC1B7/PY\nfw3xxcAE7/V4IEVEMoB+QLGIvC4iC0Xkr14Lpta9XvfWP0QkvqEPF5GJIpIrIrkFBQUHfRIWOIwx\npq5I14a3AqNEZCEwCsgH/EAMMNJLHwYcBfzAy3MnMMDbng7c3tCBVfUxVc1R1ZysrKyDLqCtN26M\nMXWFM3DkA92D3md72/ZS1a2qOkFVhwJ3eduKca2TRV43lw94EzjBS9+mThXwNK5LLGxsvXFjjKkr\nnLXhfKCviPQWkTjgcmBq8A4ikikitWW4E3gqKG+qiNQ2Fc4EvvLydPH+FeBiYFkYz2FfV5W1OIwx\nBghj4PBaCjcB04EVwCuqulxEJonIhd5uo4FVIrIa6ATc6+X147qpZonIUkCAx708z3vblgKZwB/C\ndQ7gnhoHG+MwxphaMeE8uKpOA6bV23ZP0OspwJQD5J0JDG5g+5ktXMxG2eC4McbUZbVhE/YOjttz\nHMYYA1jgaFJti8OmVTfGGMdqwybU3lVlLQ5jjHEscDRh33Mc9lUZYwxY4GjSvhaHfVXGGAMWOJpk\ng+PGGFOXBY4m2OC4McbUZbVhE/Y9AGgtDmOMAQscTaryBRCB2GiJdFGMMeawYIGjCW4Rpyjc1FjG\nGGMscDTB1hs3xpi6LHA0ocoXsIFxY4wJYjViEyqtxWGMMXVY4GhC7RiHMcYYx2rEJlT5AjbdiDHG\nBLEasQlVPuuqMsaYYGENHCIyRkRWichaEbmjgfSeIjJLRJaIyBwRyQ5K6yEiM0RkhYh8JSK9vO29\nReRz75gve8vShk1VjQ2OG2NMsLDViCISDTwIjAUGAVeIyKB6u90PTFbVwcAk4L6gtMnAX1V1IDAc\n2OFt/zPwD1XtA+wCfhSucwCotBaHMcbUEc5L6eHAWlVdr6rVwEvARfX2GQR86L2eXZvuBZgYb/lY\nVLVMVcvFPYV3JvuWm30WuDiM50BVjQ2OG2NMsHDWiN2ALUHv87xtwRYDE7zX44EUEckA+gHFIvK6\niCwUkb96LZgMoFhVfY0cEwARmSgiuSKSW1BQcNAnYXdVGWNMXZGuEW8FRonIQmAUkA/4gRhgpJc+\nDDgK+EFzDqyqj6lqjqrmZGVlHXQBq3x+EmKtq8oYY2qFM3DkA92D3md72/ZS1a2qOkFVhwJ3eduK\ncS2JRV43lw94EzgBKARSRSTmQMdsadbiMMaYusJZI84H+np3QcUBlwNTg3cQkUwRqS3DncBTQXlT\nRaS2qXAm8JWqKm4s5FJv+/eBt8J4Du7JcWtxGGPMXmELHF5L4SZgOrACeEVVl4vIJBG50NttNLBK\nRFYDnYB7vbx+XDfVLBFZCgjwuJfnduAXIrIWN+bxZBjPwVocxhhTT0zTuxw8VZ0GTKu37Z6g11PY\nd4dU/bwzgcENbF+Pu2Mr7Gr8iqqtN26MMcGsRmxE7XrjNjhujDH7WOBoRO1649biMMaYfaxGbISt\nN26MMfuzwNGIvS0Om6vKGGP2shqxEVU11lVljDH1WY3YiNrBcXuOwxhj9rHA0QgbHDfGmP1ZjdgI\nGxw3xpj9WeBohLU4jDFmf1YjNqI2cNgKgMYYs4/ViI2osq4qY4zZjwWORthzHMYYsz+rERthg+PG\nGLM/CxyNsMFxY4zZn9WIjbDAYYwx+7MasRFVPj/xMVGISKSLYowxh42wBg4RGSMiq0RkrYjc0UB6\nTxGZJSJLRGSOiGQHpflFZJH3NzVo+zMisiEobUi4yl9VY6v/GWNMfWFbAVBEooEHgXOAPGC+iExV\n1a+CdrsfmKyqz4rImcB9wNVeWoWqHigo3OatHhhWVT5bb9wYY+oL5+X0cGCtqq5X1WrgJeCievsM\nAj70Xs9uID2irMVhjDH7C2et2A3YEvQ+z9sWbDEwwXs9HkgRkQzvfYKI5IrIPBG5uF6+e73urX+I\nSHxDHy4iE738uQUFBQd1AlU+CxzGGFNfpGvFW4FRIrIQGAXkA34vraeq5gBXAg+IyNHe9juBAcAw\nIB24vaEDq+pjqpqjqjlZWVkHVbgqn9/WGzfGmHrCNsaBCwLdg95ne9v2UtWteC0OEUkGLlHVYi8t\n3/t3vYjMAYYC61R1m5e9SkSexgWfsBjaI40+lb5wHd4YY45I4Qwc84G+ItIbFzAux7Ue9hKRTKBI\nVQO4lsRT3vY0oFxVq7x9TgX+4qV1UdVt4u6RvRhYFq4TuPGMPuE6tDHGHLHCFjhU1SciNwHTgWjg\nKVVdLiKTgFxVnQqMBu4TEQU+Bm70sg8EHhWRAK477U9Bd2M9LyJZgACLgOvDdQ7GGGP2J6oa6TKE\nXU5Ojubm5ka6GMYYc0QRkQXeWHMdkR4cN8YYc4SxwGGMMaZZLHAYY4xpFgscxhhjmsUChzHGmGax\nwGGMMaZZ2sTtuCJSAGw6yOyZwM4WLM6Roi2ed1s8Z2ib523nHJqeqrrfnE1tInB8EyKS29B9zK1d\nWzzvtnjO0DbP2875m7GuKmOMMc1igcMYY0yzWOBo2mORLkCEtMXzbovnDG3zvO2cvwEb4zDGGNMs\n1uIwxhjTLBY4jDHGNIsFjkaIyBgRWSUia0XkjkiXJxxEpLuIzBaRr0RkuYjc7G1PF5GZIrLG+zct\n0mVtaSISLSILReQd731vEfnc+71fFpG4SJexpYlIqohMEZGVIrJCRE5u7b+1iPzc+297mYi8KCIJ\nrfG3FpGnRGSHiCwL2tbgbyvOv7zzXyIiJzTnsyxwHICIRAMPAmOBQcAVIjIosqUKCx/wS1UdBJwE\n3Oid5x3ALFXtC8zy3rc2NwMrgt7/GfiHqvYBdgE/ikipwuufwPuqOgA4Hnf+rfa3FpFuwM+AHFU9\nFreo3OW0zt/6GWBMvW0H+m3HAn29v4nAw835IAscBzYcWKuq61W1GngJuCjCZWpxqrpNVb/0Xpfi\nKpJuuHN91tvtWdwyva2GiGQD5wNPeO8FOBOY4u3SGs+5A3A68CSAqlarajGt/LfGrXTaTkRigERg\nG63wt1bVj4GiepsP9NteBExWZx6QKiJdQv0sCxwH1g3YEvQ+z9vWaolIL2Ao8DnQSVW3eUlfA50i\nVKxweQD4PyDgvc8AilXV571vjb93b6AAeNrrontCRJJoxb+1quYD9wObcQGjBFhA6/+tax3ot/1G\n9ZsFDgOAiCQDrwG3qOru4DR192y3mvu2RWQcsENVF0S6LIdYDHAC8LCqDgX2UK9bqhX+1mm4q+ve\nQFcgif27c9qElvxtLXAcWD7QPeh9tret1RGRWFzQeF5VX/c2b69tuv5/e/cTYlUZxnH8+9NQHAwk\nsI2SYkpEkAOBiBYMjisRcWEGaYrQrk2LIAxFDNrapiAXBYYi/sE/s4xMhlz4jzQC3WnQLMoWIYgY\nYj8X73v1Zk3OqTNz7fL7bO7ccw/nvofn3nnuec45z1sfb/RqfJNgJbBO0o+UEuQqSu1/Ti1nQH/G\newwYs32uPj9KSST9HOvVwHXbv9q+CxyjxL/fY90xXmz/0/+3JI7xXQCW1KsvZlBOqI30eEytq7X9\nz4Grtvd0vTQCbK1/bwVOTvXYJovt7bbn215Iies3tjcBp4ENdbW+2mcA2z8DP0l6oS4aBq7Qx7Gm\nlKiWSxqon/XOPvd1rLuMF9sRYEu9umo5cLOrpPVYuXP8H0haQ6mFTwe+sP1Rj4fUOkmvAt8CP/Cw\n3v8B5TzHYeA5Skv6jbYfPfH2vydpCHjP9lpJiyhHIM8Al4DNtn/v5fjaJmmQckHADOAasI3yA7Jv\nYy1pN/AG5QrCS8DblHp+X8Va0kFgiNI+/RdgF3CCv4ltTaKfUMp2t4Ftti9O+L2SOCIioomUqiIi\nopEkjoiIaCSJIyIiGkniiIiIRpI4IiKikSSOiCecpKFOB9+IJ0ESR0RENJLEEdESSZslnZd0WdLe\nOt/HLUkf1/kgTkmaW9cdlHS2zoVwvGuehMWSvpb0vaTvJD1fNz+7ax6NA/UGroieSOKIaIGkFyl3\nJ6+0PQjcAzZRmupdwgQNDAAAATBJREFUtP0SMEq5mxfgS+B92y9T7trvLD8AfGp7KbCC0tEVStfi\ndylzwyyi9FuK6ImnHr9KREzAMPAKcKEeDMyiNJT7AzhU19kPHKvzYsyxPVqX7wOOSHoamGf7OIDt\nOwB1e+dtj9Xnl4GFwJnJ362Iv0riiGiHgH22t/9pobTzkfX+bY+f7j5K98h3N3oopaqIdpwCNkh6\nFh7M9byA8h3rdGF9Ezhj+ybwm6TX6vK3gNE6A+OYpPV1GzMlDUzpXkRMQH61RLTA9hVJO4CvJE0D\n7gLvUCZLWlZfu0E5DwKlxfVnNTF0utRCSSJ7JX1Yt/H6FO5GxISkO27EJJJ0y/bsXo8jok0pVUVE\nRCM54oiIiEZyxBEREY0kcURERCNJHBER0UgSR0RENJLEERERjdwHgpxMUeY1pv0AAAAASUVORK5C\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iT_uVAAGadwg",
        "colab_type": "text"
      },
      "source": [
        "### Evaluating on Given Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2HBSqPradwh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(filename)\n",
        "pred_results = model.predict(([inputs_test, queries_test]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZ2HgR82adwi",
        "colab_type": "code",
        "outputId": "f955fcfb-0d2c-4217-b6e6-42cadfe87da0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "test_data[0][0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Mary',\n",
              " 'got',\n",
              " 'the',\n",
              " 'milk',\n",
              " 'there',\n",
              " '.',\n",
              " 'John',\n",
              " 'moved',\n",
              " 'to',\n",
              " 'the',\n",
              " 'bedroom',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 203
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjqNpoFJadwj",
        "colab_type": "code",
        "outputId": "003d10a4-24ed-4db4-d992-028e3e593f92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "story =' '.join(word for word in test_data[0][0])\n",
        "print(story)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mary got the milk there . John moved to the bedroom .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDRqrhS-adwk",
        "colab_type": "code",
        "outputId": "eecd1182-aa52-4911-e16c-1211eb748b2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "query = ' '.join(word for word in test_data[0][1])\n",
        "print(query)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Is John in the kitchen ?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoQ1AjWPadwl",
        "colab_type": "code",
        "outputId": "23d4ccd5-3a79-4b55-e40a-3a85eff467ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"True Test Answer from Data is:\",test_data[0][2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True Test Answer from Data is: no\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaIdWQX5adwn",
        "colab_type": "code",
        "outputId": "48ad162c-735b-41a4-cb77-12a2620ec08a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#Generate prediction from model\n",
        "val_max = np.argmax(pred_results[0])\n",
        "\n",
        "for key, val in tokenizer.word_index.items():\n",
        "    if val == val_max:\n",
        "        k = key\n",
        "\n",
        "print(\"Predicted answer is: \", k)\n",
        "print(\"Probability of certainty was: \", pred_results[0][val_max])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted answer is:  no\n",
            "Probability of certainty was:  0.9996698\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-RYHpqIadwo",
        "colab_type": "text"
      },
      "source": [
        "## Writing Your Own Stories and Questions\n",
        "\n",
        "Remember you can only use words from the existing vocab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RI2ZwsLmadwo",
        "colab_type": "code",
        "outputId": "0699ee23-8c95-4515-8020-5e4274ef11f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        }
      },
      "source": [
        "vocab"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.',\n",
              " '?',\n",
              " 'Daniel',\n",
              " 'Is',\n",
              " 'John',\n",
              " 'Mary',\n",
              " 'Sandra',\n",
              " 'apple',\n",
              " 'back',\n",
              " 'bathroom',\n",
              " 'bedroom',\n",
              " 'discarded',\n",
              " 'down',\n",
              " 'dropped',\n",
              " 'football',\n",
              " 'garden',\n",
              " 'got',\n",
              " 'grabbed',\n",
              " 'hallway',\n",
              " 'in',\n",
              " 'journeyed',\n",
              " 'kitchen',\n",
              " 'left',\n",
              " 'milk',\n",
              " 'moved',\n",
              " 'no',\n",
              " 'office',\n",
              " 'picked',\n",
              " 'put',\n",
              " 'the',\n",
              " 'there',\n",
              " 'to',\n",
              " 'took',\n",
              " 'travelled',\n",
              " 'up',\n",
              " 'went',\n",
              " 'yes'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 208
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAp8k3qkadwp",
        "colab_type": "code",
        "outputId": "84f8df2f-4beb-4440-ae97-a2f63591b9f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# Note the whitespace of the periods\n",
        "my_story = \"John left the kitchen . Sandra dropped the football in the garden .\"\n",
        "my_story.split()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['John',\n",
              " 'left',\n",
              " 'the',\n",
              " 'kitchen',\n",
              " '.',\n",
              " 'Sandra',\n",
              " 'dropped',\n",
              " 'the',\n",
              " 'football',\n",
              " 'in',\n",
              " 'the',\n",
              " 'garden',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yENKvVTMadwq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_question = \"Is the football in the garden ?\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIOQdnNRadws",
        "colab_type": "code",
        "outputId": "07968954-01c6-48cd-f9e7-5c7b75798d59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "my_question.split()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Is', 'the', 'football', 'in', 'the', 'garden', '?']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0sUk6PNadwt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mydata = [(my_story.split(),my_question.split(),'yes')]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2E1_XGBadwv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_story,my_ques,my_ans = vectorize_stories(mydata)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMsRPJs_adww",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_results = model.predict(([ my_story, my_ques]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gswPo9cadwx",
        "colab_type": "code",
        "outputId": "9ff7ea7d-96a7-49bf-8c0d-78cc920525c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#Generate prediction from model\n",
        "val_max = np.argmax(pred_results[0])\n",
        "\n",
        "for key, val in tokenizer.word_index.items():\n",
        "    if val == val_max:\n",
        "        k = key\n",
        "\n",
        "print(\"Predicted answer is: \", k)\n",
        "print(\"Probability of certainty was: \", pred_results[0][val_max])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted answer is:  yes\n",
            "Probability of certainty was:  0.96931225\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}